{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Text Preprocessing\n",
    "\n",
    "In this section, we will dive deeper into text preprocessing techniques. These techniques are crucial for cleaning and preparing text data for machine learning models.\n",
    "\n",
    "**Our goals for this section are:**\n",
    "1. Learn about stemming and lemmatization.\n",
    "2. Understand how to use regular expressions for text cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Stemming\n",
    "\n",
    "Stemming is the process of reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words known as a lemma. For example, the stem of the words `running`, `ran`, and `runs` is `run`.\n",
    "\n",
    "### Stemming with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "words = [\"running\", \"ran\", \"runs\", \"easily\", \"fairly\"]\n",
    "stemmed_words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "print(\"Original Words:\", words)\n",
    "print(\"Stemmed Words:\", stemmed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Lemmatization\n",
    "\n",
    "Lemmatization is similar to stemming, but it brings context to the words. It links words with similar meanings to one word. For example, the words `run`, `running`, and `ran` are all forms of the word `run`, so they would all be lemmatized to `run`.\n",
    "\n",
    "### Lemmatization with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "words = [\"running\", \"ran\", \"runs\", \"easily\", \"fairly\"]\n",
    "lemmatized_words = [lemmatizer.lemmatize(word, pos='v') for word in words] # pos='v' for verb\n",
    "\n",
    "print(\"Original Words:\", words)\n",
    "print(\"Lemmatized Words:\", lemmatized_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization with spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "text = \"The quick brown foxes are jumping over the lazy dogs.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "lemmatized_words = [token.lemma_ for token in doc]\n",
    "\n",
    "print(\"Original Text:\", text)\n",
    "print(\"Lemmatized Words:\", lemmatized_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Regular Expressions\n",
    "\n",
    "Regular expressions (regex) are a powerful tool for finding and replacing patterns in text. They are often used to remove punctuation, numbers, and other unwanted characters from text.\n",
    "\n",
    "### Using Regex to Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "text = \"This is a sample sentence with punctuation! And numbers 123.\"\n",
    "\n",
    "# Remove punctuation\n",
    "clean_text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "print(\"Original Text:\", text)\n",
    "print(\"Cleaned Text:\", clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Now it's your turn!\n",
    "1. Create a new text variable with a sentence of your choice.\n",
    "2. Lemmatize the text using either NLTK or spaCy.\n",
    "3. Use a regular expression to remove all the numbers from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Section 2\n",
    "\n",
    "Congratulations on completing the second section! You've learned about stemming, lemmatization, and regular expressions.\n",
    "\n",
    "**Next Steps:**\n",
    "1. Save this notebook.\n",
    "2. Commit your changes to Git with the message 'Complete Section 2'.\n",
    "3. When you're ready, ask me to proceed to **Section 3: Feature Engineering**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}